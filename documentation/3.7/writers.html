<div class="sect1">
<h2 id="introduction"><a class="anchor" href="#introduction"></a>Introduction to Cache Loaders and Writers</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This section documents the specifics behind the cache-through implementation in Ehcache.
Refer to the section <a href="caching-patterns.html">Cache Usage Patterns</a> if you are not familiar with terms
like <em>cache-through</em>, <em>read-through</em>, <em>write-through</em> or <em>system of record</em>.</p>
</div>
<div class="paragraph">
<p>Ehcache merges the concepts of read-through and write-through behind a single interface, the <code>CacheLoaderWriter</code>.</p>
</div>
<div class="paragraph">
<p>As indicated by its API, this interface provides methods with logical grouping:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">read-through</dt>
<dd>
<p>The <code>load(K)</code> and <code>loadAll(Iterable&lt;? super K&gt;)</code> methods cover the read-through part of cache-through.</p>
</dd>
<dt class="hdlist1">write-through</dt>
<dd>
<p>The <code>write(K, V)</code>, <code>writeAll(Iterable&lt;? extends Map.Entry&lt;? extends K, ? extends V&gt;&gt;)</code>, <code>delete(K)</code> and
<code>deleteAll(Iterable&lt;? super K&gt;)</code> methods cover the write-through part of cache-through.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>The reasoning behind having a unified interface is that if you want a read-through only cache,
you need to decide what to do about mutative method calls.
What happens if someone calls <code>put(K, V)</code> on the cache?
This risks making it inconsistent with the underlying system of record.</p>
</div>
<div class="paragraph">
<p>In this context, the unified interface forces you to make a choice: either no-op <code>write</code><strong>/<code>delete</code></strong> methods or
throwing when mutation happens.</p>
</div>
<div class="paragraph">
<p>For a write-through only cache, it remains possible by simply having no-op <code>load</code>* methods.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="write-behind"><a class="anchor" href="#write-behind"></a>Write-behind</h2>
<div class="sectionbody">
<div class="paragraph">
<p>An additional feature provided by Ehcache is <em>write-behind</em>, where writes are made asynchronously to the backing system of record.
The way this works in Ehcache is by simply telling the system to register a wrapper around your provided <code>CacheLoaderWriter</code> implementation.</p>
</div>
<div class="paragraph">
<p>From there, you will have extra configuration options around batching and coalescing of writes.</p>
</div>
<div class="paragraph">
<p>Ehcache does not support retry of failed writes at the write-behind wrapper level.
You, as the application developer and system of record owner, know better when a retry should happen and how.
So if you need that functionality, make it part of your <code>CacheLoaderWriter</code> implementation.</p>
</div>
<div class="paragraph">
<p>Write-behind introduces the following concepts:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">queue size</dt>
<dd>
<p>Indicates how many pending write operations there can be before applying back pressure on cache operations.</p>
</dd>
<dt class="hdlist1">concurrency level</dt>
<dd>
<p>Indicates how many parallel processing threads and queues there will be for write behind.
Effectively the maximum number of in-flight writes is <em>concurrency level * queue size</em>.</p>
</dd>
<dt class="hdlist1">batching and batch size</dt>
<dd>
<p>Mutative operations will be grouped in batch size sets before reaching the <code>CacheLoaderWriter</code>.
When batching, the queue size is effectively the number of pending batches there can be.
This means that the maximum number of in-flight writes becomes <em>concurrency level * queue size * batch size</em>.</p>
</dd>
<dt class="hdlist1">coalescing</dt>
<dd>
<p>When batching, coalescing means that you only send the latest mutation on a per key basis to the <code>CacheLoaderWriter</code>.</p>
</dd>
<dt class="hdlist1">maximum write delay</dt>
<dd>
<p>When batching, you can indicate the maximum write delay for an incomplete batch.
After this time has elapsed, the batch is processed even if incomplete.</p>
</dd>
</dl>
</div>
</div>
</div>
<div class="sect1">
<h2 id="cache-through"><a class="anchor" href="#cache-through"></a>Implementing Cache-Through</h2>
<div class="sectionbody">
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight nowrap"><code class="language-java" data-lang="java">CacheManager cacheManager = CacheManagerBuilder.newCacheManagerBuilder().build(true);

Cache&lt;Long, String&gt; writeThroughCache = cacheManager.createCache("writeThroughCache",
    CacheConfigurationBuilder.newCacheConfigurationBuilder(Long.class, String.class, ResourcePoolsBuilder.heap(10))
        .withLoaderWriter(new SampleLoaderWriter&lt;&gt;(singletonMap(41L, "zero"))) <i class="conum" data-value="1"></i><b>(1)</b>
        .build());

assertThat(writeThroughCache.get(41L), is("zero")); <i class="conum" data-value="2"></i><b>(2)</b>
writeThroughCache.put(42L, "one"); <i class="conum" data-value="3"></i><b>(3)</b>
assertThat(writeThroughCache.get(42L), equalTo("one"));

cacheManager.close();</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>We register a sample <code>CacheLoaderWriter</code> that knows about the mapping ("41L" maps to "zero").</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Since the cache has no content yet, this will delegate to the <code>CacheLoaderWriter</code>.
The returned mapping will populate the cache and be returned to the caller.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>While creating this cache mapping, the <code>CacheLoaderWriter</code> will be invoked to write the mapping into the system of record.</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="adding-write-behind"><a class="anchor" href="#adding-write-behind"></a>Adding Write-Behind</h3>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight nowrap"><code class="language-java" data-lang="java">CacheManager cacheManager = CacheManagerBuilder.newCacheManagerBuilder().build(true);

Cache&lt;Long, String&gt; writeBehindCache = cacheManager.createCache("writeBehindCache",
    CacheConfigurationBuilder.newCacheConfigurationBuilder(Long.class, String.class, ResourcePoolsBuilder.heap(10))
        .withLoaderWriter(new SampleLoaderWriter&lt;&gt;(singletonMap(41L, "zero"))) <i class="conum" data-value="1"></i><b>(1)</b>
        .add(WriteBehindConfigurationBuilder <i class="conum" data-value="2"></i><b>(2)</b>
            .newBatchedWriteBehindConfiguration(1, TimeUnit.SECONDS, 3)<i class="conum" data-value="3"></i><b>(3)</b>
            .queueSize(3)<i class="conum" data-value="4"></i><b>(4)</b>
            .concurrencyLevel(1) <i class="conum" data-value="5"></i><b>(5)</b>
            .enableCoalescing()) <i class="conum" data-value="6"></i><b>(6)</b>
        .build());

assertThat(writeBehindCache.get(41L), is("zero"));
writeBehindCache.put(42L, "one");
writeBehindCache.put(43L, "two");
writeBehindCache.put(42L, "This goes for the record");
assertThat(writeBehindCache.get(42L), equalTo("This goes for the record"));

cacheManager.close();</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>For write-behind you need a configured <code>CacheLoaderWriter</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Additionally, register a <code>WriteBehindConfiguration</code> on the cache by using the <code>WriteBehindConfigurationBuilder</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Here we configure write behind or batching with a batch size of 3 and a maximum write delay of 1 second.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>We also set the maximum size of the write-behind queue.</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Define the concurrency level of write-behind queue(s).
This indicates how many writer threads work in parallel to update the underlying system of record asynchronously.</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td>Enable the write coalescing behavior, which ensures that only one update per key per batch reaches the underlying system of record.</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>BatchedWriteBehindConfigurationBuilder</code> configurations are not honoured by clustered caches.
</td>
</tr>
</table>
</div>
</div>
</div>
</div>