<div class="sect1">
<h2 id="data-freshness-and-expiration"><a class="anchor" href="#data-freshness-and-expiration"></a>Data Freshness and Expiration</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="data-freshness"><a class="anchor" href="#data-freshness"></a>Data Freshness</h3>
<div class="paragraph">
<p>Data <em>freshness</em> refers to how up-to-date a copy of data (e.g. in a cache) is compared to the source version of the
data (e.g. in the system-of-record (SoR)).  A <em>stale</em> copy is considered to be out of sync (or likely to be out of
sync) with the SoR.</p>
</div>
<div class="paragraph">
<p>Databases (and other SORs) weren&#8217;t built with caching outside of the database in mind, and therefore don&#8217;t normally
come with any default mechanism for notifying external processes when data has been updated or modified.  Thus external
components that have loaded data from the SoR have no direct way of ensuring that data is not stale.</p>
</div>
</div>
<div class="sect2">
<h3 id="cache-entry-expiration"><a class="anchor" href="#cache-entry-expiration"></a>Cache Entry Expiration</h3>
<div class="paragraph">
<p>Ehcache can assist you with reducing the likelihood that stale data is used by your application by <em>expiring</em> cache
entries after some amount of configured time. Once expired, the entry is automatically removed from the cache.</p>
</div>
<div class="paragraph">
<p>For instance the cache could be configured to expire entries five seconds after they are put into the cache - which is a
time-to-live <em>TTL</em> setting.  Or to expire entries 17 seconds after the last time the entry was retrieved from the
cache - which is a time-to-idle <em>TTI</em> setting.</p>
</div>
<div class="paragraph">
<p>The expiration configuration that would be most appropriate for your cache (if any) would be a mixture of a business
and technical decision based upon the requirements and assumptions of your application.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="storage-tiers"><a class="anchor" href="#storage-tiers"></a>Storage Tiers</h2>
<div class="sectionbody">
<div class="paragraph">
<p>You can configure Ehcache to use various data storage areas.
When a cache is configured to use more than one storage area, those areas are arranged and managed as <code>tiers</code>.
They are organized in a hierarchy, with the lowest tier (farther) being called the <code>authority</code> tier and the others being part of the <code>caching</code> tier (nearer, also called <code>near cache</code>) .
The caching tier can itself be composed of more than one storage area.
The <em>hottest</em> data is kept in the caching tier, which is typically less abundant but faster than the authority tier.
All the data is kept in the authority tier, which is slower but more abundant.</p>
</div>
<div class="paragraph">
<p>Data stores supported by Ehcache include:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>On-Heap Store - Utilizes Java&#8217;s on-heap RAM memory to store cache entries. This tier utilizes the same heap memory as
your Java application, all of which must be scanned by the JVM garbage collector.  The more heap space your JVM
utilizes, the more your application performance will be impacted by garbage collection pauses.  This store is
extremely fast, but is typically your most limited storage resource.</p>
</li>
<li>
<p>Off-Heap Store - Limited in size only by available RAM.
Not subject to Java garbage collection (GC).
Is quite fast, yet slower than the On-Heap Store because data must be moved to and from the JVM heap as it is stored and re-accessed.</p>
</li>
<li>
<p>Disk Store - Utilizes a disk (file system) to store cache entries.
This type of storage resource is typically very abundant but much slower than the RAM-based stores. As for all application using disk
storage, it is recommended to use a fast and dedicated disk to optimize the throughput.</p>
</li>
<li>
<p>Clustered Store - This data store is a cache on a remote server.
The remote server may optionally have a failover server providing improved high availability.
Since clustered storage comes with performance penalties due to such factors as network latency as well as for establishing client/server consistency,
this tier, by nature, is slower than local off-heap storage.</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="images/EhcacheTerminology.png" alt="EhcacheTerminology">
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="topology-types"><a class="anchor" href="#topology-types"></a>Topology Types</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="standalone"><a class="anchor" href="#standalone"></a>Standalone</h3>
<div class="paragraph">
<p>The data set is held in the application node. Any other application nodes are independent with no
communication between them. If a standalone topology is used where there are multiple application nodes running the
same application, then their caches are completely independent.</p>
</div>
</div>
<div class="sect2">
<h3 id="distributed-clustered"><a class="anchor" href="#distributed-clustered"></a>Distributed / Clustered</h3>
<div class="paragraph">
<p>The data is held in a remote server (or array of servers) with a subset of hot data held in each application node.
This topology offers offers a selection of consistency options.
A distributed topology is the recommended approach in a clustered or scaled-out application environment.
It provides the best combination of performance, availability, and scalability.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ClusteredEhcacheTopology.png" alt="ClusteredEhcacheTopology">
</div>
</div>
<div class="paragraph">
<p>It is common for many production applications to be deployed in clusters of multiple instances for availability and scalability.
However, without a distributed cache, application clusters exhibit a number of undesirable behaviors, such as:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Cache Drift - If each application instance maintains its own cache, updates made to one cache will not appear in the
other instances. A distributed cache ensures that all of the cache instances are kept in sync with each
other.</p>
</li>
<li>
<p>Database Bottlenecks - In a single-instance application, a cache effectively shields a database from the overhead of
redundant queries. However, in a distributed application environment, each instance must load and keep its own cache
fresh. The overhead of loading and refreshing multiple caches leads to database bottlenecks as more application
instances are added. A distributed cache eliminates the per-instance overhead of loading and refreshing
multiple caches from a database.</p>
</li>
</ul>
</div>
</div>
</div>
</div>